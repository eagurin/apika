# ğŸš€ APIKI - API Knowledge Integration

> **Unleash the power of AI to conquer any API!** APIKI is a revolutionary tool that bridges the gap between natural language and APIs with cutting-edge LLM technology.

APIKI (API Knowledge Integration) is a state-of-the-art framework that transforms how developers interact with APIs, combining the intelligence of LangChain agents with the structure of OpenAPI specifications for unprecedented API interaction capabilities.

## âœ¨ Supercharged Features

- ğŸ§  **AI-Powered API Agent**: Communicate with any API using natural language through advanced LLM-driven agents
- ğŸ”Œ **Seamless API Client**: Programmatically interact with APIs using an elegantly simple yet powerful client interface
- ğŸ’» **Intelligent CLI**: Command-line interface with natural language processing for API interactions
- ğŸ“š **OpenAPI Superpowers**: Automatically discovers and adapts to API capabilities using OpenAPI specifications
- ğŸ³ **Containerization Ready**: Deploy with Docker for maximum portability and scalability
- âš¡ **Performance Optimized**: Built for speed and reliability in production environments

## ğŸ› ï¸ Quick Installation

```bash
# Using poetry (recommended for maximum dependency control)
poetry add apiki

# Using pip (for quick integration)
pip install apiki
```

## ğŸš€ Getting Started in Seconds

### ğŸ§  Unleash the API Agent

```python
import os
from dotenv import load_dotenv
from apiki.agent import APIAgent, APIAgentConfig

# Load environment variables for OpenAI API key
load_dotenv()

# Configure the agent
config = APIAgentConfig(
    openapi_url="http://localhost:7272/openapi.json",
    api_base_url="http://localhost:7272",
    api_key=os.getenv("OPENAI_API_KEY")
)

# Create the agent
agent = APIAgent(config)

# Send a natural language query to the agent
response = agent.run("Get a list of all items from the API")
print(response.output)
```

### ğŸ”Œ Direct Client Interface

```python
from apiki.client import APIClient, APIClientConfig

# Configure the client
config = APIClientConfig(
    openapi_url="http://localhost:7272/openapi.json",
    api_base_url="http://localhost:7272"
)

# Create the client
client = APIClient(config)

# Make API requests
response = client.get("/api/items")
print(response.data)
```

### ğŸ’» Command-line Magic

```bash
# Using agent mode (requires OpenAI API key)
python -m apiki.cli agent "List all available resources"

# Using client mode
python -m apiki.cli client get /api/items

# Create a resource
python -m apiki.cli client post /api/items --data '{"name": "Test Item", "description": "Created via CLI"}'

# Get information about available endpoints
python -m apiki.cli client endpoints
```

### ğŸ³ Docker Power

```bash
# Build the Docker image
docker build -t apiki .

# Run APIKI in a Docker container
docker run --rm -e OPENAI_API_KEY=your_api_key apiki agent "List all available endpoints"

# Using Docker Compose
docker-compose up --build
```

### âš™ï¸ Just Command Runner

```bash
# Install Just (macOS)
brew install just

# Install Just (using Cargo)
cargo install just

# List all available commands
just

# Run tests
just test

# Format code and run linting
just check

# Build and run with Docker
just docker-build
just docker-run agent "List all available endpoints"
```

## ğŸ”§ Advanced Configuration

### ğŸ§  API Agent Configuration

| Parameter               | Description                                       | Default                           |
|-------------------------|---------------------------------------------------|-----------------------------------|
| `openapi_url`           | URL to the OpenAPI specification                  | `http://localhost:7272/openapi.json` |
| `api_base_url`          | Base URL for the API                              | `http://localhost:7272`           |
| `model_name`            | Name of the OpenAI model to use                   | `gpt-3.5-turbo`                   |
| `temperature`           | Temperature for the model                         | `0.0`                             |
| `api_key`               | OpenAI API key                                    | `None` (uses env var)             |
| `headers`               | Headers to include in API requests                | `{}`                              |
| `allow_dangerous_requests` | Whether to allow potentially dangerous requests | `True`                            |
| `use_chat_model`        | Whether to use ChatOpenAI instead of OpenAI        | `True`                            |
| `timeout`               | Timeout for API requests in seconds               | `30`                              |
| `max_token_limit`       | Maximum number of tokens to use in the JsonSpec   | `4000`                            |
| `verbose`               | Whether to enable verbose logging                 | `True`                            |

### ğŸ”Œ API Client Configuration

| Parameter               | Description                                       | Default                           |
|-------------------------|---------------------------------------------------|-----------------------------------|
| `openapi_url`           | URL to the OpenAPI specification                  | `http://localhost:7272/openapi.json` |
| `api_base_url`          | Base URL for the API                              | `http://localhost:7272`           |
| `headers`               | Headers to include in API requests                | `{}`                              |
| `timeout`               | Timeout for API requests in seconds               | `30`                              |
| `verify_ssl`            | Whether to verify SSL certificates                | `True`                            |
| `verbose`               | Whether to enable verbose logging                 | `True`                            |

## ğŸ§ª Development

### âš¡ Using Just Command Runner

The project includes a `justfile` with common development tasks:

```bash
# Install dependencies
just install

# Run tests
just test

# Check code quality (format, lint, type check)
just check

# Build Docker image
just docker-build

# Run in Docker
just docker-run <command>
```

See the `justfile` for a complete list of available commands.

## ğŸ”¥ Technical Achievements

- **Zero-Shot API Interaction**: APIKI can interact with any API without prior training, using only the OpenAPI specification
- **LLM-Powered Intelligence**: Leverages state-of-the-art language models to understand and execute complex API operations
- **Dynamic Request Composition**: Automatically constructs API requests based on natural language instructions
- **Schema-Aware Processing**: Intelligently parses and validates API schemas for accurate interactions
- **Adaptive Error Handling**: Robust error recovery and intelligent retry mechanisms
- **High-Performance Architecture**: Optimized for production workloads with minimal latency
- **Comprehensive Testing**: Extensive test suite ensuring reliability across diverse scenarios

## ğŸ“‹ Requirements

- ğŸ Python 3.10+
- ğŸ”— LangChain ecosystem
- ğŸ”‘ OpenAI API key (for agent mode)
- ğŸ“„ An API with an OpenAPI specification
- ğŸ³ Docker (optional, for containerized usage)
- âš™ï¸ Just command runner (optional, for simplified development workflow)

## ğŸŒŸ Why APIKI?

APIKI represents a quantum leap in API interaction technology. By combining advanced LLM capabilities with structured API specifications, it enables developers to interact with APIs in ways previously thought impossible. Whether you're building complex integrations, exploring new APIs, or automating workflows, APIKI provides the intelligence and flexibility needed to master any API challenge.

**Ready to revolutionize how you work with APIs? Start using APIKI today!**
